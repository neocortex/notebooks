{
 "metadata": {
  "name": "",
  "signature": "sha256:904c48bef2f1fbbe4850e92cb6d346cd71b75450e8dc15c165df3b84930faeaf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Kaggle Competition: Sentiment Analysis of Movie Reviews"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML('<iframe src= http://3.bp.blogspot.com/-VZHnGIWJhaA/TcGPDCgwUUI/AAAAAAAABRw/1I0KoUpKBfg/s1600/rottentomatoes.jpg'\n",
      "     'width=\"300\" height=\"278\"> </iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src= http://3.bp.blogspot.com/-VZHnGIWJhaA/TcGPDCgwUUI/AAAAAAAABRw/1I0KoUpKBfg/s1600/rottentomatoes.jpgwidth=\"300\" height=\"278\"> </iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x7f5071155c90>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The present notebook is an entry to [Kaggle's Sentiment Analysis of Movie Reviews](http://www.kaggle.com/c/sentiment-analysis-on-movie-reviews) competition. The task is to classify movie reviews from the [Rotten Tomatoes](www.rottentomatoes.com) movie review dataset into one of 5 sentiment classes:\n",
      "\n",
      "* negative\n",
      "* somewhat negative\n",
      "* neutral\n",
      "* somewhat positive\n",
      "* positive"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A few Configurations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here a simply configure two thingsL First, I specify where my NLTK data is stored (this is not needed, if NLTK data is stored in one of the default paths after downloading. And second, I prevent the printing of annoying warning messages to stdout."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import warnings\n",
      "nltk.data.path = ['/home/rafael/libraries/nltk/nltk_data/']\n",
      "warnings.filterwarnings('ignore')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First things first: Let's load the training data into a DataFrame ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "raw_data =  pd.read_csv('train.tsv', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "... and extract the movie review phrases and the corresponding sentiment classes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrases = raw_data.Phrase.values\n",
      "y = raw_data.Sentiment.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Phrase Cleaning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first step of the data preprocessing and feature extraction steps I plan to perform is to clean the phrases. This basically involves **removing punctuation** and **converting the phrases to lowercase**.\n",
      "\n",
      "Therefor, I wrote a stateless transform class (meaning that it the data doesn't need to be fitted before being transformed), that inherits from ``sklearn.base.TransformerMixin`` and given a list of phrases (as strings) returns a list of \"cleaned\" phrases. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import PhraseCleaner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline = [PhraseCleaner()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature I: Mulitlabel Classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first feature I am going to use are the distances to the decision boundaries of a multilabel classifier, trained in a one-to-rest fashion. Specifically, for each sentiment class a classifier is trained to separate that class against all other taken together. Hence, we will end up with a total of 5 classifiers (equals #sentiment_classes). For each phrase, we now compute the distance to the decision boundaries of each of the 5 classifiers. This gives us a measure of the certainty that phrase *x* belongs to sentiment class *y*. The higher the value, the larger the distance to the decision boundary, the higher the certainty of class membership.\n",
      "\n",
      "This feature can be seen as some sort of dimensionality reduction, because we go from originally **number unique word** to **number of sentiment classes (=5)**.\n",
      "\n",
      "Before we can use this transformation, however, we need to bring our phrases into a format that scikit-learn can handle. Therefore we use the ``CountVectorizer`` that converts our collection of phrases to a matrix of token counts. The number of features resulting from this step will be equal to the vocabulary size found by analyzing the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from transformations import ClassDistanceMapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step1 = CountVectorizer(binary=False,\n",
      "                        tokenizer=lambda x: x.split(),\n",
      "                        min_df=0,\n",
      "                        ngram_range=(1, 1),\n",
      "                        stop_words=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step2 = ClassDistanceMapper()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat1 = make_pipeline(step1, step2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature II: Harvard General Inquirer Valence"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second feature is engineered as follows: For each word in a phrase we query the [Harvard General Inquirer](http://www.wjh.harvard.edu/~inquirer/) database for that word. If the word is present, we check if it has a positive or a negative valence (if any at all). We sum all the positive and negative word occurances in for each phrase. Hence, we obtain a two-dimensional feature, where one columns is 'number of positive word occurances' and the second column is 'number of negative word occurances'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import InquirerValence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat2 = InquirerValence()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature III: Lui Bing's Opinion Lexicon"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This feature is similar to the second one: For each word in a phrase we query [Bing Liu's sentiment lexicon](http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html) for positive or negative opinion. Summing all positive and negative word occurances in for each phrase, we again obatain a two-dimensional feature with  'number of positive word occurances' and the second column is 'number of negative word occurances', respectively."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import LiuOpinion"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat3 = LiuOpinion()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature IV: WordNet Synsets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, the last feature consists of mapping each phrase to a string consisting of all WordNet synsets of each word in that phrase. The other two steps are the same as above: Applying the ``CountVectorizer`` and the  ``ClassDistanceMapper`` to the synset strings. Hence, we obtain another feature set of size 5. This time it is the distances of the synset strings to the decision boundaries of each 1-vs-rest classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import SynsetsMapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step1 = SynsetsMapper()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step2 = CountVectorizer(binary=False,\n",
      "                        tokenizer=lambda x: x.split(),\n",
      "                        min_df=0,\n",
      "                        ngram_range=(1, 1),\n",
      "                        stop_words=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step3 = ClassDistanceMapper()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat4 = make_pipeline(step1, step2, step3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature V"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import SentiWordNetMapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat5 = SentiWordNetMapper()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Putting all together"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have the features we want to use, we build a ``sklearn.pipeline.Pipeline``, in which each step and each feature is computed successively. Therefor, we unify our features and add them to a pipeline containing the ``PhraseCleaner`` (which is to be applied in the beginning before computing any of the features)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import make_union"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = make_union(feat1, feat2, feat3, feat4, feat5)\n",
      "pipeline.append(features)\n",
      "pip = make_pipeline(*pipeline)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use our pipeline to plugin the raw review phrases along with the target sentiment classes. ``Scikit-learn`` takes care for us of fitting and transforming each step of the pipeline. We end up with a matrix of size **#phrases x 14**. Fourteen because our first two features are 5-dimensional (boundary distances for each class) and the others are 2-dimensional (positive and negative word occurances)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = pip.fit_transform(phrases, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "(156060, 16)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Train a classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have our features, we can train a classifier and see how it performs. A decent choice is always ``RandomForestClassifier``. I perform a 5-fold cross-validation on the training data and compute the mean score (classification accuracy)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.cross_validation import cross_val_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(RandomForestClassifier(n_estimators=100), X, y, cv=5, n_jobs=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "0.71789678139102397"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that the accuracy is around 67%. This is not bad at all. Keep in mind that a random classifier on 5 classes would have an accuracy of approximately 20%."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Train and run on test data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we know our classifier's accuray, we train the classifier again on the complete training set ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=100, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "... and run the classifier on the test set. Of course, before predicting the labels, we first need to applying our fitted feature extraction pipeline on the raw phrases of the test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data =  pd.read_csv('test.tsv', sep='\\t')\n",
      "test_phrases = test_data.Phrase.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test = pip.transform(test_phrases)\n",
      "preds = rf.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Write predictions to file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The last remaining step is to write all predicted labels into a file in the correct format (a PhraseID column and a Sentiment column including a header) in order to submitted to the Kaggle competition."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('submission.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(('PhraseId', 'Sentiment'))\n",
      "    for i, x in enumerate(preds):\n",
      "        writer.writerow((test_data.ix[i]['PhraseId'], x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    }
   ],
   "metadata": {}
  }
 ]
}