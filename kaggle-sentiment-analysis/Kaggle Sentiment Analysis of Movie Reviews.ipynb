{
 "metadata": {
  "name": "",
  "signature": "sha256:cdeda52caa3a5a7c5979f2c964826dd283820f18ce2078b7d9f324119aa31a79"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Kaggle Competition: Sentiment Analysis of Movie Reviews"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML('<iframe src= http://3.bp.blogspot.com/-VZHnGIWJhaA/TcGPDCgwUUI/AAAAAAAABRw/1I0KoUpKBfg/s1600/rottentomatoes.jpg'\n",
      "     'width=\"300\" height=\"278\"> </iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src= http://3.bp.blogspot.com/-VZHnGIWJhaA/TcGPDCgwUUI/AAAAAAAABRw/1I0KoUpKBfg/s1600/rottentomatoes.jpgwidth=\"300\" height=\"278\"> </iframe>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x7f5071155c90>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Introduction"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The present notebook is an entry to [Kaggle's Sentiment Analysis of Movie Reviews](http://www.kaggle.com/c/sentiment-analysis-on-movie-reviews) competition. The task is to classify movie reviews from the [Rotten Tomatoes](www.rottentomatoes.com) movie review dataset into one of 5 sentiment classes:\n",
      "\n",
      "* negative\n",
      "* somewhat negative\n",
      "* neutral\n",
      "* somewhat positive\n",
      "* positive"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Please note that in order to run this notebook you need to download all datasets that are being used here."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### A few Configurations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here a simply configure two things. First, I specify where my NLTK data is stored (this is not needed, if NLTK data is stored in one of the default paths). And second, I prevent the printing of annoying warning messages to stdout."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import warnings\n",
      "nltk.data.path = ['/home/rafael/libraries/nltk/nltk_data/']\n",
      "warnings.filterwarnings('ignore')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load the data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First things first: Let's load the training data into a DataFrame ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "raw_data =  pd.read_csv('train.tsv', sep='\\t')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "... and extract the movie review phrases and the corresponding sentiment classes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "phrases = raw_data.Phrase.values\n",
      "y = raw_data.Sentiment.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Phrase Cleaning"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a first step of the data preprocessing and feature extraction process, I intend to clean the phrases. This basically involves **removing punctuation** and **converting the phrases to lowercase**.\n",
      "\n",
      "Therefor, I wrote a stateless transform class (meaning that the data doesn't need to be fitted before being transformed), that inherits from ``sklearn.base.TransformerMixin``, and given a list of phrases (as strings) returns a list of \"cleaned\" phrases. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import PhraseCleaner"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipeline = [PhraseCleaner()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature I: Mulitlabel Classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The first feature I am going to use are the distancesof the datapoints (vectorized phrases) to the decision boundaries of a multilabel classifier, trained in a one-to-rest fashion. Specifically, for each sentiment class, a classifier is trained to separate that class against all other taken together. Hence, we will end up with a total of 5 classifiers (equals #sentiment_classes). For each phrase, we now compute the distance to the decision boundaries of each of the 5 classifiers. This gives us a measure of the certainty that phrase *x* belongs to sentiment class *y*. The higher the value, the larger the distance to the decision boundary, the higher the certainty of class membership.\n",
      "\n",
      "This feature can be seen as a form of dimensionality reduction, because we go from originally **number unique words (vocabulary)** to **number of sentiment classes (=5)**.\n",
      "\n",
      "Before we can use this transformation, however, we need to bring our phrases into a format that ``scikit-learn`` can handle. Therefore we use the ``CountVectorizer`` that converts our collection of phrases to a matrix of token counts. The number of features resulting from this step will be equal to the vocabulary size found by analyzing the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.pipeline import make_pipeline\n",
      "from transformations import ClassDistanceMapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step1 = CountVectorizer(binary=False,\n",
      "                        tokenizer=lambda x: x.split(),\n",
      "                        min_df=0,\n",
      "                        ngram_range=(1, 1),\n",
      "                        stop_words=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step2 = ClassDistanceMapper()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat1 = make_pipeline(step1, step2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature II: Harvard General Inquirer Valence"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The second feature is engineered as follows: For each word in a phrase we query the [Harvard General Inquirer](http://www.wjh.harvard.edu/~inquirer/) database for that word. If the word is present, we check if it has a positive or a negative valence (if any at all). We sum all the positive and negative word occurences in each phrase. Hence, we obtain a two-dimensional feature, where one columns is 'number of positive word occurences' and the second column is 'number of negative word occurences'."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import InquirerValence"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat2 = InquirerValence()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature III: Lui Bing's Opinion Lexicon"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This feature is similar to the second one: For each word in a phrase we query [Bing Liu's sentiment lexicon](http://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html) for positive or negative opinion. Summing all positive and negative word occurences in each phrase, we again obatain a two-dimensional feature with 'number of positive word occurences' in the first column and the 'number of negative word occurences' in the second column, respectively."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import LiuOpinion"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat3 = LiuOpinion()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature IV: SentiWordNet"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[SentiWordNet](http://sentiwordnet.isti.cnr.it/) attaches positive and negative real-valued sentiment scores to [WordNet synsets](http://www.nltk.org/howto/wordnet.html). Hence, similarly as the preceeding two features, we sum over all positive and negative word occurences that we find in the SentiWordNet database for each phrase, and once again obtain a two-dimensional feature vector. Note that I do not work on the raw [SentiWordnet download](http://sentiwordnet.isti.cnr.it/download.php), but on a preprocessed version of it using ``clean_sentiwordnet.py``."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import SentiWordNetMapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat4 = SentiWordNetMapper()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Feature IV: WordNet Synsets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, the last feature consists of mapping each phrase to a string consisting of all [WordNet](http://wordnet.princeton.edu/) synsets of each word in that phrase. The other two steps for this feature are the same as with Feature I: Applying the ``CountVectorizer`` and the  ``ClassDistanceMapper`` to the synset strings. Hence, we obtain another feature of dimensionality 5. This time it is the distances of the synset strings to the decision boundaries of each 1-vs-rest classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from transformations import SynsetsMapper"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step1 = SynsetsMapper()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step2 = CountVectorizer(binary=False,\n",
      "                        tokenizer=lambda x: x.split(),\n",
      "                        min_df=0,\n",
      "                        ngram_range=(1, 1),\n",
      "                        stop_words=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "step3 = ClassDistanceMapper()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feat5 = make_pipeline(step1, step2, step3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Putting all together"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have the features we want to use, we build a ``sklearn.pipeline.Pipeline``, in which each step and each feature is computed successively. Therefor, we unify our features and add them to a pipeline containing the ``PhraseCleaner`` (which is to be applied in the beginning before computing any of the features)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import make_union"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = make_union(feat1, feat2, feat3, feat4, feat5)\n",
      "pipeline.append(features)\n",
      "pip = make_pipeline(*pipeline)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now use our pipeline to plugin the raw review phrases along with the target sentiment classes. ``Scikit-learn`` takes care for us of fitting and transforming each step of the pipeline. We end up with a matrix of size **#phrases x 16**. Sixteen because the first and the last features are 5-dimensional (boundary distances for each class) and the others are 2-dimensional (positive and negative word occurences in three different lexica)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = pip.fit_transform(phrases, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "(156060, 16)"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Train a classifier"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we have our feature matrix, we can train a classifier and see how it performs. A decent choice is always ``RandomForestClassifier``. I perform a 5-fold cross-validation on the training data and compute the mean score (classification accuracy)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.cross_validation import cross_val_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores = cross_val_score(RandomForestClassifier(n_estimators=100), X, y, cv=5, n_jobs=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scores.mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "0.71789678139102397"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can see that the accuracy is around 72%. This is not bad at all. Keep in mind that a random classifier on 5 classes would have an accuracy of approximately 20%."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Train and run on test data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that we know our classifier's accuracy, we train the classifier again on the complete training set ..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf = RandomForestClassifier(n_estimators=100)\n",
      "rf.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=100, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "... and run the fitted classifier on the test set. Of course, before predicting the labels, we first need to apply our fitted feature extraction pipeline on the raw phrases of the test set."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "test_data =  pd.read_csv('test.tsv', sep='\\t')\n",
      "test_phrases = test_data.Phrase.values"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_test = pip.transform(test_phrases)\n",
      "preds = rf.predict(X_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Write predictions to file"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The last remaining step is to write all predicted labels into a file in the correct format (a PhraseID column and a Sentiment column including a header) in order to be submitted to the Kaggle competition."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open('submission.csv', 'w') as f:\n",
      "    writer = csv.writer(f)\n",
      "    writer.writerow(('PhraseId', 'Sentiment'))\n",
      "    for i, x in enumerate(preds):\n",
      "        writer.writerow((test_data.ix[i]['PhraseId'], x))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Shortcomings"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are still a few shortcomings and TODOs to look at in the present analysis.\n",
      "\n",
      "* Investigate how the different features contribute to the classification, especially the several sentiment lexicon features.\n",
      "* Perform a gridsearch on the hyperparameters of the ``RandomForestClassifier``.\n",
      "* Try different classifiers (with decision boundaries) for the multiclass classification in ``ClassDistanceMapper``.\n",
      "* Do spell-checking.\n",
      "* Engineer other features."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}