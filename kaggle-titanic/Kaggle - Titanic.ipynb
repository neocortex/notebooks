{
 "metadata": {
  "name": "",
  "signature": "sha256:74ad7e06afede892d531eebd1c5370212a8b8a1a77fe4172b96e7ebbbaf99c07"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is in order to suppress output of annoying warnings, especially DeprecationWarnings\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Some imports that will be needed along the way\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.cross_validation import cross_val_score\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
      "from sklearn.lda import LDA\n",
      "from sklearn.grid_search import GridSearchCV"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load data\n",
      "raw_data = pd.read_csv('train.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_data.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's drop some columns that don't seem to be useful as features. For instance, passenger ID and names are unique, which means they contain no predictive information. In a later step I plan to include ticket and cabin information, as these are not solely unique."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ids = raw_data.PassengerId.values\n",
      "raw_data = raw_data.drop('PassengerId', axis=1)\n",
      "raw_data = raw_data.drop('Name', axis=1)\n",
      "raw_data = raw_data.drop('Ticket', axis=1)\n",
      "raw_data = raw_data.drop('Cabin', axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fill NaNs with means (we could try median here too)\n",
      "means = raw_data.mean(skipna=True)\n",
      "data = raw_data.fillna(means)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Fill NaNs of Embarked with most frequent value. There are only two missing values in the data.\n",
      "data.Embarked = data.Embarked.fillna(data.Embarked.value_counts().index[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Replace categorical variables with dummies\n",
      "new_sex_column = pd.get_dummies(data.Sex, prefix='Sex')\n",
      "data = data.drop('Sex', axis=1)\n",
      "data = pd.concat((data, new_sex_column), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the Sex information we can think about dropping one of the columns, because they are redundant, e.g. where male=1, female=0 and vice versa. Not sure how this affects the predictions, but let's keep it in mind.\n",
      "\n",
      "``` data = data.rename(columns={'Sex_male': 'Sex'})\n",
      "data = data.drop('Sex_female', axis=1) ```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_embarked_column = pd.get_dummies(data.Embarked, prefix='Embarked')\n",
      "data = data.drop('Embarked', axis=1)\n",
      "data = pd.concat((data, new_embarked_column), axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Extract targets\n",
      "targets = data.Survived.values\n",
      "data = data.drop('Survived', axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fit():\n",
      "X, y = load('train.csv')\n",
      "# Scale\n",
      "#scalerx = StandardScaler().fit(X)\n",
      "#X = scalerx.transform(X)\n",
      "\n",
      "# Classifier\n",
      "# clf = GradientBoostingClassifier(n_estimators=3000)\n",
      "clf = RandomForestClassifier(n_estimators=3000)\n",
      "# clf = SVC()\n",
      "# clf = LDA()\n",
      "# clf = LogisticRegression(C=10.)\n",
      "\n",
      "# Gridsearch parameters\n",
      "param_grid_forest = {'min_samples_leaf': [1, 2, 3, 5],\n",
      "                     'max_depth': [5, 6, 7],\n",
      "                     'max_features': [1., .9, .8, .5],\n",
      "                     'min_samples_split': [5, 6, 7, 8]}\n",
      "param_grid_boosting = {'learning_rate': [0.03, 0.02, 0.01],\n",
      "                       'max_depth': [3, 4, 5, 6],\n",
      "                       'max_features': [.7, .6, .5],\n",
      "                       'min_samples_split': [6, 8, 10],\n",
      "                       'subsample': [1., .9, 0.8, 0.7]}\n",
      "param_grid_svc = {'C': [0.5, 1, 1.5, 2, 3, 5, 10],\n",
      "                  'gamma': [0.01, 0.1, 0.2, 0.25, 0.3, .5],\n",
      "                  'kernel': ['rbf', 'sigmoid']}\n",
      "\n",
      "# Gridsearch\n",
      "gs = GridSearchCV(clf, param_grid=param_grid_forest, cv=5,\n",
      "                  verbose=3, n_jobs=2)\n",
      "gs.fit(X, y, cv=5, verbose=5)\n",
      "scores = cross_val_score(gs.best_estimator_, X, y, cv=10)\n",
      "print scores.min(), scores.mean(), scores.max()\n",
      "return gs\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}